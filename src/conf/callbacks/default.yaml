lr_monitor:
  _target_: pytorch_lightning.callbacks.LearningRateMonitor
  logging_interval: 'epoch'

model_ckpt:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  monitor: 'val/loss'
  mode: 'min'
  save_top_k: 4
  dirpath: '/weights'
  filename: 'epoch{epoch:02d}-val_loss{val/loss:.2f}'
  auto_insert_metric_name: False

model_ckpt_usdr:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  monitor: 'val/usdr'
  mode: 'max'
  save_top_k: 4
  dirpath: ${..model_ckpt.dirpath}
  filename: 'epoch{epoch:02d}-val_usdr{val/usdr:.2f}'
  auto_insert_metric_name: False

early_stop:
  _target_: pytorch_lightning.callbacks.EarlyStopping
  monitor: 'val/loss'
  mode: "min"
  patience: 10
  min_delta: 1e-4

ema:
  _target_: utils.callbacks.EMA
  decay: 0.9999
  validate_original_weights: False
  every_n_steps: 1
#
#log_on_epoch:
#  _target_: utils.callbacks.OverrideEpochStepCallback
